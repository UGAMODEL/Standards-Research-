{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the fine tuned model\n",
    "\n",
    "loaded_model = BertForSequenceClassification.from_pretrained('savedmodels')\n",
    "loaded_tokenizer = BertTokenizer.from_pretrained('savedmodels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requirement_to_embedding(model, tokenizer, requirement):\n",
    "    input = tokenizer(requirement, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    input = input.to(\"cpu\")  # copy input to CPU\n",
    "    output = model(**input)  # run model without labels to get logits & encoded layers\n",
    "    hidden_states = output.hidden_states\n",
    "    embedding = hidden_states[12][0][0]  # each layer has output of size (batch_size, sequence_length, hidden_size); here we are getting the [CLS] token from the final layer\n",
    "    embedding = embedding.detach().numpy()\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import numpy as np\n",
    "embeddings = [ requirement_to_embedding ( model , tokenizer , requirement ) for\n",
    "requirement in requirements ]\n",
    "embedd_array = np . stack ( embeddings )\n",
    "embedd_array . shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Specify the perplexity and learning rate values\n",
    "perplexity_value = 50  # You can adjust this value\n",
    "learning_rate_value = 10  # You can adjust this value\n",
    "\n",
    "# Initialize the t-SNE model with specified perplexity and learning rate\n",
    "tsne = TSNE(n_components=2, perplexity=perplexity_value, learning_rate=learning_rate_value, random_state=42)\n",
    "\n",
    "# Fit the t-SNE model to your data\n",
    "embeddings_2d = tsne.fit_transform(embedd_array)\n",
    "\n",
    "# Create binary labels as a list (0 for 'requirement', 1 for 'standard')\n",
    "labels = df.label.map({'standard': 1, 'requirement': 0}).tolist()\n",
    "\n",
    "# Define colors and markers for the two classes\n",
    "colors = sns.color_palette('Set1', n_colors=2)  # Custom color palette\n",
    "markers = 'o'  # Circle markers for both classes\n",
    "\n",
    "# Convert embeddings_2d array into a DataFrame with index values\n",
    "df = pd.DataFrame(embeddings_2d, columns=['Dimension 1', 'Dimension 2'])\n",
    "df['label'] = labels\n",
    "\n",
    "# Create a scatter plot of the t-SNE embeddings for both classes\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.set(style='whitegrid')  # Set Seaborn style with gridlines\n",
    "\n",
    "for label in set(labels):\n",
    "    df_label = df[df['label'] == label]\n",
    "    sns.scatterplot(data=df_label, x='Dimension 1', y='Dimension 2', hue='label', palette=[colors[int(label)]], marker=markers, edgecolor='k', s=100)\n",
    "    \n",
    "\n",
    "\n",
    "# Create legends for the classes\n",
    "class_labels = ['requirement', 'standard']  # Map the labels back to their original names\n",
    "legend_handles = [plt.Line2D([0], [0], marker=markers, color='w', label=class_labels[int(label)], markersize=10,\n",
    "                              markerfacecolor=colors[int(label)]) for label in set(labels)]\n",
    "plt.legend(handles=legend_handles, title='Classes')\n",
    "\n",
    "plt.title(\"t-SNE Visualization of Embeddings with Class Labels and IDs\", fontsize=16)\n",
    "#plt.xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
    "#plt.ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.grid(False)  # Turn off gridlines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "plt.savefig('tsne_visualization_perp6_nottrained.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
